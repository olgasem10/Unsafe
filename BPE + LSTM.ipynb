{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip uninstall pandas -y","execution_count":33,"outputs":[{"output_type":"stream","text":"Found existing installation: pandas 0.24.2\nUninstalling pandas-0.24.2:\n  Successfully uninstalled pandas-0.24.2\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pandas","execution_count":34,"outputs":[{"output_type":"stream","text":"Collecting pandas\n  Downloading pandas-1.2.3-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n\u001b[K     |████████████████████████████████| 9.9 MB 7.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2020.5)\nRequirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.19.5)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.12.0)\nInstalling collected packages: pandas\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npandas-profiling 2.8.0 requires requests>=2.23.0, but you have requests 2.21.0 which is incompatible.\nosmnx 1.0.1 requires requests>=2.25, but you have requests 2.21.0 which is incompatible.\ngoogle-colab 1.0.0 requires pandas~=0.24.0, but you have pandas 1.2.3 which is incompatible.\nautogluon-core 0.1.0b20210219 requires tornado>=5.0.1, but you have tornado 4.5.3 which is incompatible.\u001b[0m\nSuccessfully installed pandas-1.2.3\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/unsafe/train_randst0.csv')\ntest = pd.read_csv('/kaggle/input/unsafe/val_randst0.csv')\ntrain = train[[\"text\", \"unsafe\"]]\ntest = test[[\"text\", \"unsafe\"]]","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.loc[(train['unsafe'] >= 0.8) | (train['unsafe'] <= 0.2)]","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def binary(prob):\n    if prob < 0.5:\n        return 0.\n    else:\n        return 1.0","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['unsafe'] = train['unsafe'].apply(binary)\ntest['unsafe'] = test['unsafe'].apply(binary)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.sample(frac=1)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"(                                                     text  unsafe\n 44157   Стащил когда-то и б. Дайте соус, по пикче не г...     0.0\n 128870  Каперсы всегда были отвратителтельны на вкус, ...     0.0\n 130118  и че толку ждать, ну понравился человек сама/с...     0.0\n 75764          Хорошо, что хронометриста не прислали ;)))     0.0\n 21494   Вот, сидят в своей пещере и не знают, когда ин...     1.0\n ...                                                   ...     ...\n 106842  Сокол это конечно показатель. Я нигде не говор...     0.0\n 50636   Вот это подготовка! Девчонки - красотки! Хрупк...     0.0\n 123155   fs, стало быть? Нормально, поиграть можно, да...     0.0\n 126467              А что на счёт сроков давности штрафа?     0.0\n 23715   да да, в однополые пары тоже пишут - \"есть люб...     1.0\n \n [120120 rows x 2 columns],\n                                                     text  unsafe\n 0                       уровень ссачнее, чем ад в доом 3     1.0\n 1      У нас несколько спортсменов и спортсменок в сп...     1.0\n 2      Я уж думал нахлебались праздников Запада ...а ...     1.0\n 3      Лол, большая часть около NUMBER% и так на нога...     1.0\n 4      Не, ну тут действительно в какой то степени ма...     1.0\n ...                                                  ...     ...\n 24496                Почему все так вокруг Киану пляшут?     0.0\n 24497  Проблема то не в том, что ты деньги проиграл. ...     0.0\n 24498  Не не не, не говори. Пусть остается в блаженно...     0.0\n 24499  На иврите будет אין חניה  , а не то что там на...     0.0\n 24500  Директор может предоставить беспроцентный заем...     0.0\n \n [24501 rows x 2 columns])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = train['text'].tolist()\ny_train = train['unsafe'].tolist()\nx_test = test['text'].tolist()\ny_test = test['unsafe'].tolist()","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install youtokentome","execution_count":10,"outputs":[{"output_type":"stream","text":"Collecting youtokentome\n  Downloading youtokentome-1.0.6-cp37-cp37m-manylinux2010_x86_64.whl (1.7 MB)\n\u001b[K     |████████████████████████████████| 1.7 MB 866 kB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: Click>=7.0 in /opt/conda/lib/python3.7/site-packages (from youtokentome) (7.1.2)\nInstalling collected packages: youtokentome\nSuccessfully installed youtokentome-1.0.6\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import youtokentome as yttm","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yttm_train = '\\n'.join(x_train)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = 100000\ntrain_path = '/kaggle/working/yttm_train.txt'\nmodel_path = '/kaggle/working/pretrained_bpe.model'","execution_count":21,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"with open(train_path, 'w') as f:\n    f.write(yttm_train)","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yttm.BPE.train(data=train_path, vocab_size=vocab_size, model=model_path)","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"<youtokentome.youtokentome.BPE at 0x7fbb7257bd90>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = yttm.BPE(model=model_path)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer.encode('Крокозябра')","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"[6353, 638, 1507, 1209]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer.decode([4,1])","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"['<UNK>']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_len = 45","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class UnsafeData(Dataset):\n\n    def __init__(self, texts, targets, tokenizer, max_len, pad_index = 0):\n        \n        super().__init__()\n        \n        self.texts = texts\n        self.targets = targets        \n        self.max_len = max_len\n        self.pad_index = pad_index\n\n    def __len__(self):\n        \n        return len(self.texts)\n    \n    def padding(self, text):\n        \n        text = text[:self.max_len]        \n        text += [self.pad_index] * (self.max_len - len(text))        \n        return text\n\n    \n    def __getitem__(self, index):\n        x = self.texts[index]\n        y = self.targets[index]\n        \n        x = tokenizer.encode(x)\n        x = self.padding(x)\n        \n        x = torch.tensor(x).long()\n        y = torch.tensor(y).float()\n        \n        return x, y","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = UnsafeData(x_train, y_train, tokenizer, max_len)\ntest_dataset = UnsafeData(x_test, y_test, tokenizer, max_len)","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_dataset), len(test_dataset)","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"(120120, 24501)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset[23000]","execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"(tensor([  703,   955,   621,   969, 23864, 20989,  4478,  1019,  1793,   669,\n          1023,  3498,   665,   877,  9734,   621, 30377,  2312, 58534,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0]),\n tensor(1.))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=32, shuffle = True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle = True)","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for batch in test_loader:\n    break\nbatch","execution_count":35,"outputs":[{"output_type":"execute_result","execution_count":35,"data":{"text/plain":"[tensor([[  877,   783,   619,  ...,     0,     0,     0],\n         [33467,  2351, 23926,  ...,     0,     0,     0],\n         [ 1108,   705,   784,  ...,     0,     0,     0],\n         ...,\n         [ 5573,  3394,  4828,  ...,     0,     0,     0],\n         [  799,  1292,   878,  ...,     0,     0,     0],\n         [  724,   722,   703,  ...,     0,     0,     0]]),\n tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n         0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x, y in test_loader:\n    break\n\nx.shape, y.shape","execution_count":36,"outputs":[{"output_type":"execute_result","execution_count":36,"data":{"text/plain":"(torch.Size([32, 45]), torch.Size([32]))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.type()","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"'torch.FloatTensor'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch import nn","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Classifier(nn.Module):\n    \n    #define all the layers used in model\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n                 bidirectional, dropout):\n        \n        #Constructor\n        super().__init__()          \n        \n        #embedding layer\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        \n        #lstm layer\n        self.lstm = nn.LSTM(embedding_dim, \n                           hidden_dim, \n                           num_layers=n_layers, \n                           bidirectional=bidirectional, \n                           dropout=dropout,\n                           batch_first=True)\n        \n        #dense layer\n        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n        \n        #activation function\n        self.act = nn.Sigmoid()\n        \n    def forward(self, text, text_lengths):\n        \n        #text = [batch size,sent_length]\n        embedded = self.embedding(text)\n        #embedded = [batch size, sent_len, emb dim]\n      \n        #packed sequence\n        #packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths,batch_first=True)\n        \n        packed_output, (hidden, cell) = self.lstm(embedded)\n        #hidden = [batch size, num layers * num directions,hid dim]\n        #cell = [batch size, num layers * num directions,hid dim]\n        \n        #concat the final forward and backward hidden state\n        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n                \n        #hidden = [batch size, hid dim * num directions]\n        dense_outputs=self.fc(hidden)\n\n        #Final activation function\n        outputs=self.act(dense_outputs)\n        \n        return outputs","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Classifier(\n    vocab_size = 100000,\n    embedding_dim = 400,\n    hidden_dim = 256,\n    output_dim = 1,\n    n_layers = 6,\n    bidirectional = True,\n    dropout = 0.4\n)","execution_count":69,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters())\ncriterion = nn.BCELoss()","execution_count":74,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def metrics(true, predictions):\n    \n    rounded_preds = torch.round(predictions)\n    \n    precision, recall, f1, _ = precision_recall_fscore_support(true, rounded_preds, average='binary', zero_division = 0)\n    acc = accuracy_score(true, rounded_preds)\n    #roc_auc = roc_auc_score(true, predictions)\n    \n    return {\n        'accuracy': acc,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall\n        #'roc_auc': roc_auc\n    }\n    \n    ","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda')\nmodel.to(device)","execution_count":71,"outputs":[{"output_type":"execute_result","execution_count":71,"data":{"text/plain":"Classifier(\n  (embedding): Embedding(100000, 400)\n  (lstm): LSTM(400, 256, num_layers=6, batch_first=True, dropout=0.4, bidirectional=True)\n  (fc): Linear(in_features=512, out_features=1, bias=True)\n  (act): Sigmoid()\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, loader, optimizer, criterion, last_n_losses=200, verbose=True):\n\n    losses = []\n    f_scores = []\n    accuracy_scores = []\n    precision_scores = []\n    recall_scores = []\n    #roc_auc_scores = []\n\n    progress_bar = tqdm(total=len(loader), disable=not verbose, desc='Train')\n\n    model.train()\n\n    for x, y in loader:\n\n        x = x.to(device)\n        y = y.to(device)\n        \n        optimizer.zero_grad()\n        \n        yhat = model(x, 45).squeeze()\n        \n        loss = criterion(yhat, y)\n        loss.backward()\n        optimizer.step()\n        \n        cur_metrics = metrics(y.cpu(), yhat.detach().cpu())\n\n\n        losses.append(loss.item())\n        f_scores.append(cur_metrics['f1'])\n        accuracy_scores.append(cur_metrics['accuracy'])\n        precision_scores.append(cur_metrics['precision'])\n        recall_scores.append(cur_metrics['recall'])\n        #roc_auc_scores.append(cur_metrics['roc_auc'])\n        \n\n        progress_bar.set_postfix(loss=np.mean(losses[-last_n_losses:]), f1=np.mean(f_scores[-last_n_losses:]),\n                                accuracy=np.mean(accuracy_scores[-last_n_losses:]))\n        \n        progress_bar.update()\n\n    progress_bar.close()\n    \n    return {'loss': np.sum(losses)/len(loader), 'f_score': np.sum(f_scores)/len(loader), 'accuracy': np.sum(accuracy_scores)/len(loader),\n           'precision': np.sum(precision_scores)/len(loader), 'recall': np.sum(recall_scores)/len(loader)}","execution_count":54,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tqdm._instances.clear()","execution_count":73,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, loader, criterion, last_n_losses=200, verbose=True):\n\n    losses = []\n    f_scores = []\n    accuracy_scores = []\n    precision_scores = []\n    recall_scores = []\n    #roc_auc_scores = []\n\n    progress_bar = tqdm(total=len(loader), disable=not verbose, desc='Eval')\n\n    model.eval()\n    with torch.no_grad():\n\n        for x, y in loader:\n\n            x = x.to(device)\n            y = y.to(device)\n        \n            yhat = model(x, 45).squeeze()\n        \n            loss = criterion(yhat, y)\n        \n            cur_metrics = metrics(y.cpu(), yhat.detach().cpu())\n\n\n            losses.append(loss.item())\n            f_scores.append(cur_metrics['f1'])\n            accuracy_scores.append(cur_metrics['accuracy'])\n            precision_scores.append(cur_metrics['precision'])\n            recall_scores.append(cur_metrics['recall'])\n            #roc_auc_scores.append(cur_metrics['roc_auc'])\n        \n\n            progress_bar.set_postfix(loss=np.mean(losses[-last_n_losses:]), f1=np.mean(f_scores[-last_n_losses:]),\n                                accuracy=np.mean(accuracy_scores[-last_n_losses:]))\n        \n            progress_bar.update()\n\n        progress_bar.close()\n    \n    return {'loss': np.sum(losses)/len(loader), 'f_score': np.sum(f_scores)/len(loader), 'accuracy': np.sum(accuracy_scores)/len(loader),\n           'precision': np.sum(precision_scores)/len(loader), 'recall': np.sum(recall_scores)/len(loader)}","execution_count":55,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_best_model_path = '/kaggle/working/best_model_state_dict.pth'\nsave_best_optimizer_path = '/kaggle/working/best_optimizer_state_dict.pth'","execution_count":51,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model.state_dict(), save_best_model_path)","execution_count":166,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_epochs = 7\nbest_valid_loss = float('inf')\npatience = 0\nfor epoch in range(n_epochs):\n     \n    #train the model\n    train_metrics = train(model, train_loader, optimizer, criterion)\n    \n    #evaluate the model\n    valid_metrics = evaluate(model, test_loader, criterion)\n    \n    print(train_metrics)\n    print(valid_metrics)\n    \n    #save the best model\n    if valid_metrics['loss'] < best_valid_loss:\n        best_valid_loss = valid_metrics['loss']\n        torch.save(model.state_dict(), save_best_model_path)\n        torch.save(optimizer.state_dict(), save_best_optimizer_path)\n    else:\n        patience +=1\n        if patience>3:\n            break\n    \n   ","execution_count":75,"outputs":[{"output_type":"stream","text":"Train: 100%|██████████| 3754/3754 [05:00<00:00, 12.48it/s, accuracy=0.73, f1=0, loss=0.558]        \nEval: 100%|██████████| 766/766 [00:14<00:00, 52.15it/s, accuracy=0.696, f1=0, loss=0.611]\n","name":"stderr"},{"output_type":"stream","text":"{'loss': 0.573664595511408, 'f_score': 0.021848227686293503, 'accuracy': 0.7218605709465459, 'precision': 0.07735276104349094, 'recall': 0.013952134997333844}\n{'loss': 0.6046996908383955, 'f_score': 0.0, 'accuracy': 0.6988549825935597, 'precision': 0.0, 'recall': 0.0}\n","name":"stdout"},{"output_type":"stream","text":"Train: 100%|██████████| 3754/3754 [04:57<00:00, 12.63it/s, accuracy=0.794, f1=0.53, loss=0.448] \nEval: 100%|██████████| 766/766 [00:14<00:00, 52.72it/s, accuracy=0.741, f1=0.504, loss=0.538]\n","name":"stderr"},{"output_type":"stream","text":"{'loss': 0.4682883356256757, 'f_score': 0.4968301171302024, 'accuracy': 0.7780367607884923, 'precision': 0.6341697316624061, 'recall': 0.44301352218155304}\n{'loss': 0.5445108435872952, 'f_score': 0.48558470372112206, 'accuracy': 0.7324148327738407, 'precision': 0.5705544691021193, 'recall': 0.4449263554710106}\n","name":"stdout"},{"output_type":"stream","text":"Train: 100%|██████████| 3754/3754 [04:57<00:00, 12.61it/s, accuracy=0.851, f1=0.706, loss=0.352]\nEval: 100%|██████████| 766/766 [00:14<00:00, 51.28it/s, accuracy=0.731, f1=0.495, loss=0.599]\nTrain:   0%|          | 2/3754 [00:00<05:08, 12.15it/s, accuracy=0.953, f1=0.932, loss=0.217]","name":"stderr"},{"output_type":"stream","text":"{'loss': 0.33010024393794063, 'f_score': 0.7309711384650253, 'accuracy': 0.8633374400639318, 'precision': 0.7769905437595196, 'recall': 0.7153892186766925}\n{'loss': 0.5899195364887969, 'f_score': 0.5026747877529175, 'accuracy': 0.7365935440755937, 'precision': 0.5777960284642296, 'recall': 0.4690991267602003}\n","name":"stdout"},{"output_type":"stream","text":"Train: 100%|██████████| 3754/3754 [04:58<00:00, 12.57it/s, accuracy=0.908, f1=0.825, loss=0.244]\nEval: 100%|██████████| 766/766 [00:14<00:00, 52.14it/s, accuracy=0.731, f1=0.5, loss=0.699]  \nTrain:   0%|          | 2/3754 [00:00<05:10, 12.07it/s, accuracy=0.953, f1=0.902, loss=0.259]","name":"stderr"},{"output_type":"stream","text":"{'loss': 0.21885627167191224, 'f_score': 0.8466225085839, 'accuracy': 0.9200297460486593, 'precision': 0.8643222640047595, 'recall': 0.8462262964079603}\n{'loss': 0.6933154677947881, 'f_score': 0.4927205643696674, 'accuracy': 0.7310258143727465, 'precision': 0.5698781020256216, 'recall': 0.45854003509888497}\n","name":"stdout"},{"output_type":"stream","text":"Train: 100%|██████████| 3754/3754 [04:58<00:00, 12.58it/s, accuracy=0.947, f1=0.893, loss=0.158]\nEval: 100%|██████████| 766/766 [00:15<00:00, 50.94it/s, accuracy=0.73, f1=0.5, loss=0.789]   \nTrain:   0%|          | 2/3754 [00:00<05:04, 12.34it/s, accuracy=0.953, f1=0.885, loss=0.127]","name":"stderr"},{"output_type":"stream","text":"{'loss': 0.13764838898119297, 'f_score': 0.9153161202759574, 'accuracy': 0.9560718566862014, 'precision': 0.9259462907305209, 'recall': 0.9148304610971884}\n{'loss': 0.7770965414087704, 'f_score': 0.49839104859395406, 'accuracy': 0.7314104656222803, 'precision': 0.5632033559070496, 'recall': 0.4717250319519556}\n","name":"stdout"},{"output_type":"stream","text":"Train: 100%|██████████| 3754/3754 [04:58<00:00, 12.56it/s, accuracy=0.966, f1=0.936, loss=0.11]  \nEval: 100%|██████████| 766/766 [00:14<00:00, 52.20it/s, accuracy=0.723, f1=0.504, loss=0.976]","name":"stderr"},{"output_type":"stream","text":"{'loss': 0.09167837153859218, 'f_score': 0.9494041308321293, 'accuracy': 0.9736697522642515, 'precision': 0.9584049399105496, 'recall': 0.946450436565882}\n{'loss': 0.9917727066471433, 'f_score': 0.5090480121844906, 'accuracy': 0.7200302281487008, 'precision': 0.5375705090869811, 'recall': 0.5102103941596723}\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}