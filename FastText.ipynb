{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom nltk.tokenize import wordpunct_tokenize\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn\nfrom torch.autograd import Variable\nfrom torch.nn import functional as F","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/unsafe/train_randst0.csv')\ntest_df = pd.read_csv('/kaggle/input/unsafe/val_randst0.csv')\ntrain_df = train_df[[\"text\", \"unsafe\"]]\ntest_df = test_df[[\"text\", \"unsafe\"]]","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.loc[(train_df['unsafe'] >= 0.8) | (train_df['unsafe'] <= 0.2)]","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def binary(val):\n    return round(val)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['unsafe'] = train_df['unsafe'].apply(binary)\ntest_df['unsafe'] = test_df['unsafe'].apply(binary)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, test_df","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"(                                                     text  unsafe\n 0       я думал что левиафаны - это те медленные страх...       1\n 1       А был бы этот полицейский в Петербурге, так пе...       1\n 2       Напоминаю, что пора искать актис невзрослого п...       1\n 3       курю лет пятнадцать никаких проблем кроме како...       1\n 4       окей, я тогда проведу парад гетеросексуалов, п...       1\n ...                                                   ...     ...\n 138825      Перед клиентом отвечает банк, а не сотрудник.       0\n 138826  Так воооот откуда я их знаю, какое старое виде...       0\n 138827  Да потом просто \"такие вот люди\" начинают жало...       0\n 138829  А теперь давай фоточки не миллионеров, а обычн...       0\n 138830  Не нашел информации о том, что он был доктором...       0\n \n [120120 rows x 2 columns],\n                                                     text  unsafe\n 0                       уровень ссачнее, чем ад в доом 3       1\n 1      У нас несколько спортсменов и спортсменок в сп...       1\n 2      Я уж думал нахлебались праздников Запада ...а ...       1\n 3      Лол, большая часть около NUMBER% и так на нога...       1\n 4      Не, ну тут действительно в какой то степени ма...       1\n ...                                                  ...     ...\n 24496                Почему все так вокруг Киану пляшут?       0\n 24497  Проблема то не в том, что ты деньги проиграл. ...       0\n 24498  Не не не, не говори. Пусть остается в блаженно...       0\n 24499  На иврите будет אין חניה  , а не то что там на...       0\n 24500  Директор может предоставить беспроцентный заем...       0\n \n [24501 rows x 2 columns])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = train_df['text'].tolist()\ny_train = train_df['unsafe'].tolist()\nx_test = test_df['text'].tolist()\ny_test = test_df['unsafe'].tolist()","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Готовые векторы fasttext"},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz","execution_count":9,"outputs":[{"output_type":"stream","text":"--2021-03-11 10:44:14--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1306357571 (1.2G) [binary/octet-stream]\nSaving to: ‘cc.ru.300.vec.gz’\n\ncc.ru.300.vec.gz    100%[===================>]   1.22G  44.3MB/s    in 32s     \n\n2021-03-11 10:44:47 (38.4 MB/s) - ‘cc.ru.300.vec.gz’ saved [1306357571/1306357571]\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!gunzip cc.ru.300.vec.gz","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pad_token = 'PAD'\n\nvocab = dict()\nembeddings = list()\n\nvocab_size = 400000\nembedding_dim = 300\n\nvocab[pad_token] = len(vocab)\nembeddings.append(np.zeros(embedding_dim))","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('cc.ru.300.vec', 'r') as f:\n    a = f.readline()\n    for line in f:\n        parts = line.strip().split()\n        token = ' '.join(parts[:-embedding_dim])\n        if token in vocab:\n            continue\n        word_vector = np.array(list(map(float, parts[-embedding_dim:])))\n        \n        vocab[token] = len(vocab)\n        embeddings.append(word_vector)\n        \n        if len(vocab) == vocab_size:\n            break","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings = np.stack(embeddings)\nembeddings.shape","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"(400000, 300)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_len = 45","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class UnsafeData(Dataset):\n\n    def __init__(self, texts, targets, vocab, max_len, pad_index = 0):\n        \n        super().__init__()\n        \n        self.texts = texts\n        self.targets = targets        \n        self.max_len = max_len\n        self.pad_index = pad_index\n        \n        self.vocab = vocab\n\n    def __len__(self):\n        \n        return len(self.texts)\n    \n    \n    def tokenization(self, text):\n        \n        tokens = wordpunct_tokenize(text)        \n        token_indices = [self.vocab[tok] for tok in tokens if tok in self.vocab]\n        \n        return token_indices\n    \n    def padding(self, text):\n        \n        text = text[:self.max_len]        \n        text += [self.pad_index] * (self.max_len - len(text))        \n        return text\n\n    \n    def __getitem__(self, index):\n        x = self.texts[index]\n        y = self.targets[index]\n        \n        x = self.tokenization(x)\n        x = self.padding(x)\n        \n        x = torch.tensor(x).long()\n        y = torch.tensor(y).float()\n        \n        return x, y","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = UnsafeData(x_train, y_train, vocab, max_len)\ntest_dataset = UnsafeData(x_test, y_test, vocab, max_len)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_dataset), len(test_dataset)","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"(120120, 24501)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train[23000]","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"'не расстраивайтесь, что его быстро отпустят. Главное, что он в отделение попал, а там уже и героин в чемодане найдётся и какая-нибудь порнография и экстремистские репосты в телефоне'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset[23000]","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"(tensor([    12,  75546,      1,     20,     40,    478, 121841,      2,   2786,\n              1,     20,     53,      4,   2777,   3574,      1,     28,    202,\n             73,      3,  77816,      4, 113093,  40576,      3,   2332,     15,\n           6459, 111797,      3, 144472, 202000,      4,  10982,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0]),\n tensor(1.))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=32, shuffle = True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle = True)","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x, y in test_loader:\n    break\n\nx.shape, y.shape","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"(torch.Size([32, 45]), torch.Size([32]))"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Модель RCNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings = torch.tensor(embeddings).float()","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RCNN(nn.Module):\n\n    \n    def __init__(self, embeddings, embedding_dim, hidden_size, hidden_size_linear, class_num, dropout, n_layers):\n        super(RCNN, self).__init__()\n        self.embedding = nn.Embedding.from_pretrained(embeddings, padding_idx=0)\n        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True, bidirectional=True, dropout=dropout, num_layers=n_layers)\n        self.W = nn.Linear(embedding_dim + 2*hidden_size, hidden_size_linear)\n        self.fc = nn.Linear(hidden_size_linear, class_num)\n        \n        self.act = nn.Sigmoid()\n\n        \n    def forward(self, x):\n        # x = |bs, seq_len|\n        x_emb = self.embedding(x)\n        # x_emb = |bs, seq_len, embedding_dim|\n        output, _ = self.lstm(x_emb)\n        # output = |bs, seq_len, 2*hidden_size|\n        output = torch.cat([output, x_emb], 2)\n        # output = |bs, seq_len, embedding_dim + 2*hidden_size|\n        output = self.W(output).transpose(1, 2)\n        # output = |bs, seq_len, hidden_size_linear| -> |bs, hidden_size_linear, seq_len|\n        output = F.max_pool1d(output, output.size(2)).squeeze(2)\n        # output = |bs, hidden_size_linear|\n        output = self.fc(output)\n        # output = |bs, class_num|\n        return self.act(output)","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RCNN(\n    embeddings = embeddings,\n    embedding_dim = 300,\n    hidden_size = 300,\n    hidden_size_linear = 128,\n    class_num = 1,\n    n_layers = 4,\n    dropout = 0.5\n)","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model(x).size()","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"torch.Size([32, 1])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters())\ncriterion = nn.BCELoss()","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def metrics(true, predictions):\n    \n    rounded_preds = torch.round(predictions)\n    \n    precision, recall, f1, _ = precision_recall_fscore_support(true, rounded_preds, average='weighted', zero_division = 0)\n    acc = accuracy_score(true, rounded_preds)\n    #roc_auc = roc_auc_score(true, predictions)\n    \n    return {\n        'accuracy': acc,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall\n        #'roc_auc': roc_auc\n    }\n    \n    ","execution_count":43,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda')\nmodel.to(device)","execution_count":46,"outputs":[{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"RCNN(\n  (embedding): Embedding(400000, 300, padding_idx=0)\n  (lstm): LSTM(300, 300, num_layers=4, batch_first=True, dropout=0.5, bidirectional=True)\n  (W): Linear(in_features=900, out_features=128, bias=True)\n  (fc): Linear(in_features=128, out_features=1, bias=True)\n  (act): Sigmoid()\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, loader, optimizer, criterion, last_n_losses=200, verbose=True):\n\n    losses = []\n    f_scores = []\n    accuracy_scores = []\n    precision_scores = []\n    recall_scores = []\n    #roc_auc_scores = []\n\n    progress_bar = tqdm(total=len(loader), disable=not verbose, desc='Train')\n\n    model.train()\n\n    for x, y in loader:\n\n        x = x.to(device)\n        y = y.to(device)\n        \n        optimizer.zero_grad()\n        \n        yhat = model(x).squeeze()\n        \n        loss = criterion(yhat, y)\n        loss.backward()\n        optimizer.step()\n        \n        cur_metrics = metrics(y.cpu(), yhat.detach().cpu())\n\n\n        losses.append(loss.item())\n        f_scores.append(cur_metrics['f1'])\n        accuracy_scores.append(cur_metrics['accuracy'])\n        precision_scores.append(cur_metrics['precision'])\n        recall_scores.append(cur_metrics['recall'])\n        #roc_auc_scores.append(cur_metrics['roc_auc'])\n        \n\n        progress_bar.set_postfix(loss=np.mean(losses[-last_n_losses:]), f1=np.mean(f_scores[-last_n_losses:]),\n                                accuracy=np.mean(accuracy_scores[-last_n_losses:]))\n        \n        progress_bar.update()\n\n    progress_bar.close()\n    \n    return {'loss': np.sum(losses)/len(loader), 'f_score': np.sum(f_scores)/len(loader), 'accuracy': np.sum(accuracy_scores)/len(loader),\n           'precision': np.sum(precision_scores)/len(loader), 'recall': np.sum(recall_scores)/len(loader)}","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tqdm._instances.clear()","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, loader, criterion, last_n_losses=200, verbose=True):\n\n    losses = []\n    f_scores = []\n    accuracy_scores = []\n    precision_scores = []\n    recall_scores = []\n    #roc_auc_scores = []\n\n    progress_bar = tqdm(total=len(loader), disable=not verbose, desc='Eval')\n\n    model.eval()\n    with torch.no_grad():\n\n        for x, y in loader:\n\n            x = x.to(device)\n            y = y.to(device)\n        \n            yhat = model(x).squeeze()\n        \n            loss = criterion(yhat, y)\n        \n            cur_metrics = metrics(y.cpu(), yhat.detach().cpu())\n\n\n            losses.append(loss.item())\n            f_scores.append(cur_metrics['f1'])\n            accuracy_scores.append(cur_metrics['accuracy'])\n            precision_scores.append(cur_metrics['precision'])\n            recall_scores.append(cur_metrics['recall'])\n            #roc_auc_scores.append(cur_metrics['roc_auc'])\n        \n\n            progress_bar.set_postfix(loss=np.mean(losses[-last_n_losses:]), f1=np.mean(f_scores[-last_n_losses:]),\n                                accuracy=np.mean(accuracy_scores[-last_n_losses:]))\n        \n            progress_bar.update()\n\n        progress_bar.close()\n    \n    return {'loss': np.sum(losses)/len(loader), 'f_score': np.sum(f_scores)/len(loader), 'accuracy': np.sum(accuracy_scores)/len(loader),\n           'precision': np.sum(precision_scores)/len(loader), 'recall': np.sum(recall_scores)/len(loader)}","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_best_model_path = '/kaggle/working/best_model_state_dict.pth'\nsave_best_optimizer_path = '/kaggle/working/best_optimizer_state_dict.pth'","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_epochs = 7\nbest_valid_loss = float('inf')\npatience = 0\nfor epoch in range(n_epochs):\n     \n    #train the model\n    train_metrics = train(model, train_loader, optimizer, criterion)\n    \n    #evaluate the model\n    valid_metrics = evaluate(model, test_loader, criterion)\n    \n    print(train_metrics)\n    print(valid_metrics)\n    \n    #save the best model\n    if valid_metrics['loss'] < best_valid_loss:\n        best_valid_loss = valid_metrics['loss']\n        torch.save(model.state_dict(), save_best_model_path)\n        torch.save(optimizer.state_dict(), save_best_optimizer_path)\n    else:\n        patience +=1\n        if patience>3:\n            break\n    \n   ","execution_count":50,"outputs":[{"output_type":"stream","text":"Train: 100%|██████████| 3754/3754 [03:18<00:00, 18.89it/s, accuracy=0.784, f1=0.769, loss=0.465]\nEval: 100%|██████████| 766/766 [00:11<00:00, 65.12it/s, accuracy=0.755, f1=0.741, loss=0.504]\n","name":"stderr"},{"output_type":"stream","text":"{'loss': 0.4828137460546285, 'f_score': 0.7485742820326823, 'accuracy': 0.7746764562244718, 'precision': 0.7631495961252673, 'recall': 0.7746764562244718}\n{'loss': 0.5074483891146613, 'f_score': 0.7422692265866033, 'accuracy': 0.7561524773094616, 'precision': 0.7550186176469228, 'recall': 0.7561524773094616}\n","name":"stdout"},{"output_type":"stream","text":"Train: 100%|██████████| 3754/3754 [03:18<00:00, 18.88it/s, accuracy=0.799, f1=0.783, loss=0.445]\nEval: 100%|██████████| 766/766 [00:11<00:00, 64.24it/s, accuracy=0.759, f1=0.737, loss=0.507]\n","name":"stderr"},{"output_type":"stream","text":"{'loss': 0.4499317804509233, 'f_score': 0.7787348709526101, 'accuracy': 0.792918109572012, 'precision': 0.7938788806810664, 'recall': 0.792918109572012}\n{'loss': 0.4998512322535403, 'f_score': 0.7418788733460003, 'accuracy': 0.7613938362551287, 'precision': 0.7593719915915885, 'recall': 0.7613938362551287}\n","name":"stdout"},{"output_type":"stream","text":"Train: 100%|██████████| 3754/3754 [03:18<00:00, 18.88it/s, accuracy=0.797, f1=0.785, loss=0.441]\nEval: 100%|██████████| 766/766 [00:11<00:00, 64.86it/s, accuracy=0.757, f1=0.732, loss=0.506]\n","name":"stderr"},{"output_type":"stream","text":"{'loss': 0.4358515429787326, 'f_score': 0.7876578042237112, 'accuracy': 0.8003518469188421, 'precision': 0.8023475489934392, 'recall': 0.8003518469188421}\n{'loss': 0.49396109907807634, 'f_score': 0.7405235279301529, 'accuracy': 0.7628255936839489, 'precision': 0.7621384316164349, 'recall': 0.7628255936839489}\n","name":"stdout"},{"output_type":"stream","text":"Train: 100%|██████████| 3754/3754 [03:18<00:00, 18.92it/s, accuracy=0.807, f1=0.796, loss=0.427]\nEval: 100%|██████████| 766/766 [00:11<00:00, 64.22it/s, accuracy=0.771, f1=0.759, loss=0.487]\n","name":"stderr"},{"output_type":"stream","text":"{'loss': 0.42369382437288794, 'f_score': 0.7966916505444869, 'accuracy': 0.8079076762564377, 'precision': 0.8114353165577556, 'recall': 0.8079076762564377}\n{'loss': 0.4927181245530554, 'f_score': 0.7548162286709772, 'accuracy': 0.7666196537361681, 'precision': 0.7673781475010625, 'recall': 0.7666196537361681}\n","name":"stdout"},{"output_type":"stream","text":"Train: 100%|██████████| 3754/3754 [03:18<00:00, 18.90it/s, accuracy=0.82, f1=0.81, loss=0.412]  \nEval: 100%|██████████| 766/766 [00:11<00:00, 63.90it/s, accuracy=0.774, f1=0.762, loss=0.499]\nTrain:   0%|          | 2/3754 [00:00<03:34, 17.48it/s, accuracy=0.854, f1=0.846, loss=0.383]","name":"stderr"},{"output_type":"stream","text":"{'loss': 0.41024466378135, 'f_score': 0.80571532996075, 'accuracy': 0.8154718300479489, 'precision': 0.8195157155094174, 'recall': 0.8154718300479489}\n{'loss': 0.5010131045631266, 'f_score': 0.7542180569894014, 'accuracy': 0.7665128061668531, 'precision': 0.7671131261995193, 'recall': 0.7665128061668531}\n","name":"stdout"},{"output_type":"stream","text":"Train: 100%|██████████| 3754/3754 [03:18<00:00, 18.90it/s, accuracy=0.823, f1=0.816, loss=0.387]\nEval: 100%|██████████| 766/766 [00:11<00:00, 64.28it/s, accuracy=0.772, f1=0.758, loss=0.511]\nTrain:   0%|          | 2/3754 [00:00<03:24, 18.38it/s, accuracy=0.844, f1=0.832, loss=0.338]","name":"stderr"},{"output_type":"stream","text":"{'loss': 0.39637428208328207, 'f_score': 0.8133243130759508, 'accuracy': 0.8219010832889363, 'precision': 0.8262839668876089, 'recall': 0.8219010832889363}\n{'loss': 0.5116566867414405, 'f_score': 0.7553526431855613, 'accuracy': 0.7701300820589333, 'precision': 0.769323224480295, 'recall': 0.7701300820589333}\n","name":"stdout"},{"output_type":"stream","text":"Train: 100%|██████████| 3754/3754 [03:18<00:00, 18.87it/s, accuracy=0.83, f1=0.824, loss=0.382] \nEval: 100%|██████████| 766/766 [00:12<00:00, 63.16it/s, accuracy=0.755, f1=0.751, loss=0.515]\n","name":"stderr"},{"output_type":"stream","text":"{'loss': 0.3795214213359432, 'f_score': 0.82381760912425, 'accuracy': 0.8314270333866097, 'precision': 0.836019396684565, 'recall': 0.8314270333866097}\n{'loss': 0.5156627208305713, 'f_score': 0.7564544109890723, 'accuracy': 0.761296702101206, 'precision': 0.766289687633515, 'recall': 0.761296702101206}\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}